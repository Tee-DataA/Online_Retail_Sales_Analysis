{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Online Retail Sales Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Write your notebook objective here, for example, \"Fetch data from Kaggle and save as raw data\", or \"engineer features for modelling\"\n",
        "\n",
        "- 3 csvs:\n",
        "- 10% of the dataset focusing on UK Sales\n",
        "- UK Customer Revenue\n",
        "- Global Sales Revenue\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Write down which data or information you need to run the notebook \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Write here which files, code or artefacts you generate by the end of the notebook \n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* If you have any additional comments that don't fit in the previous bullets, please state them here. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/mahahussain/Desktop/Hackathon2/Online_Retail_Sales_Analysis'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/mahahussain/Desktop/Hackathon2'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Section 1: ETL Process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Extract: Importing Libraries, Extracting & Describing the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- This section involves importing libraries necessary for subsequent data analysis and visualisation tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These libraries are imported to handle data manipulation (pandas, numpy), create visualisations (seaborn, matplotlib, plotly), and perform statistical analysis (scipy.stats)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importing necessary libraries for data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import scipy.stats as st"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We opted to access the CSV file, Online Retail.csv, directly from a GitHub repository using the raw URL of the file. \n",
        "\n",
        "By using this method, the CSV file is fetched directly from the GitHub repository without needing to download it manually, making the process efficient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Storing the url of the dataset and storing it in a DataFrame\n",
        "url = \"https://raw.githubusercontent.com/bvhadra/Online_Retail_Sales_Analysis/refs/heads/main/Online%20Retail.csv\"\n",
        "df = pd.read_csv(url) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  InvoiceNo StockCode                          Description  Quantity  \\\n",
            "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
            "1    536365     71053                  WHITE METAL LANTERN         6   \n",
            "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
            "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
            "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
            "\n",
            "           InvoiceDate  UnitPrice  CustomerID         Country  \n",
            "0  2010-12-01 08:26:00       2.55       17850  United Kingdom  \n",
            "1  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n",
            "2  2010-12-01 08:26:00       2.75       17850  United Kingdom  \n",
            "3  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n",
            "4  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n"
          ]
        }
      ],
      "source": [
        "# Display the first few rows of the DataFrame to confirm successful import\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       InvoiceNo StockCode                      Description  Quantity  \\\n",
            "541904    581587     22613      PACK OF 20 SPACEBOY NAPKINS        12   \n",
            "541905    581587     22899     CHILDREN'S APRON DOLLY GIRL          6   \n",
            "541906    581587     23254    CHILDRENS CUTLERY DOLLY GIRL          4   \n",
            "541907    581587     23255  CHILDRENS CUTLERY CIRCUS PARADE         4   \n",
            "541908    581587     22138    BAKING SET 9 PIECE RETROSPOT          3   \n",
            "\n",
            "                InvoiceDate  UnitPrice  CustomerID Country  \n",
            "541904  2011-12-09 12:50:00       0.85       12680  France  \n",
            "541905  2011-12-09 12:50:00       2.10       12680  France  \n",
            "541906  2011-12-09 12:50:00       4.15       12680  France  \n",
            "541907  2011-12-09 12:50:00       4.15       12680  France  \n",
            "541908  2011-12-09 12:50:00       4.95       12680  France  \n"
          ]
        }
      ],
      "source": [
        "# Display the last few rows of the DataFrame to confirm successful import\n",
        "print(df.tail())  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then used the `df.describe()` function to generate a summary of key statistics for the numerical columns, helping us understand the data's distribution and identify potential outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quantity</th>\n",
              "      <th>UnitPrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>541909.000000</td>\n",
              "      <td>541909.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>9.552250</td>\n",
              "      <td>4.611114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>218.081158</td>\n",
              "      <td>96.759853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-80995.000000</td>\n",
              "      <td>-11062.060000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.080000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>4.130000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>80995.000000</td>\n",
              "      <td>38970.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Quantity      UnitPrice\n",
              "count  541909.000000  541909.000000\n",
              "mean        9.552250       4.611114\n",
              "std       218.081158      96.759853\n",
              "min    -80995.000000  -11062.060000\n",
              "25%         1.000000       1.250000\n",
              "50%         3.000000       2.080000\n",
              "75%        10.000000       4.130000\n",
              "max     80995.000000   38970.000000"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Generates a summary of statistics (count, mean, std, min, max, etc.) for numerical columns in the DataFrame.\n",
        "df[['Quantity', 'UnitPrice']].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Findings:\n",
        "\n",
        "**Count**: Both **Quantity** and **UnitPrice** have 500k+ non-null entries, indicating a large dataset. Given our technical limitations, we will need to truncate this data.\n",
        "\n",
        "1. **Mean**: The average **Quantity** is 9.55, and the average **UnitPrice** is 4.61, providing insight into typical values for these columns.\n",
        "\n",
        "2. **Standard Deviation**: The standard deviations (218.08 for **Quantity** and 96.76 for **UnitPrice**) show significant variability in both columns, suggesting that the data includes a wide spread of values.\n",
        "\n",
        "**Min/Max**: The extreme values are notable:\n",
        "1. The **Quantity** column includes a minimum of **-80,995** and a maximum of **80,995**, with negative quantities being particularly concerning.\n",
        "\n",
        "2. Similarly, the **UnitPrice** has a negative minimum of **-11,062.06** and a maximum of **38,970**, indicating the presence of abnormal negative values for prices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We started by inspecting the counts of the null/not-null values in the columns using `df.count()` and `df.isna()` respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Count of non-NA values in each column:\n",
            "InvoiceNo      541909\n",
            "StockCode      541909\n",
            "Description    540455\n",
            "Quantity       541909\n",
            "InvoiceDate    541909\n",
            "UnitPrice      541909\n",
            "CustomerID     541909\n",
            "Country        541909\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Display the count of non null values in each column\n",
        "print(\"\\nCount of non-NA values in each column:\")\n",
        "print(df.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Missing values in each column:\n",
            "InvoiceNo         0\n",
            "StockCode         0\n",
            "Description    1454\n",
            "Quantity          0\n",
            "InvoiceDate       0\n",
            "UnitPrice         0\n",
            "CustomerID        0\n",
            "Country           0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values in each column\n",
        "print(\"\\nMissing values in each column:\")\n",
        "print(df.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset has no missing values in most columns, except for **Description**, which contains 1,454 missing entries. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Next Steps:\n",
        "\n",
        "Following the extraction stage, we will be addressing the following key issues:\n",
        "\n",
        "1. **Negative Values**: We need to look into the negative values found in both **Quantity** and **UnitPrice**, especially the extreme ones, as they could be errors or invalid entries. These might be caused by mistakes in data entry, returns, or system glitches.\n",
        "\n",
        "2. **Clean the Data**: We will remove or correct the negative values in both columns, making sure only valid positive numbers are used in the analysis.\n",
        "\n",
        "3. **Outlier Detection**: Weâ€™ll also need to deal with the extreme outliers in **Quantity** and **UnitPrice**. \n",
        "\n",
        "4. **Feature Engineering**: We will also perform feature engineering to ensure that the name column is properly standardised, especially since some items have the same name but come in different colours (e.g., \"WHITE HANGING HEART T-LIGHT HOLDER\" in different colorus). This will help avoid confusion and ensure consistency.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Transform: Data pre-processing & Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- This section involves cleaning the data, removing missing and invalid values. It also includes feature engineering and truncation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.2.1 Filtering the data for the UK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Following the request from our stakeholders, we will focus exclusively on the United Kingdom (UK) for the analysis.\n",
        "\n",
        "First, we want to confirm that the United Kingdom does not have any alternate names in the data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique values in 'Country' column: ['United Kingdom' 'France' 'Australia' 'Netherlands' 'Germany' 'Norway'\n",
            " 'EIRE' 'Switzerland' 'Spain' 'Poland' 'Portugal' 'Italy' 'Belgium'\n",
            " 'Lithuania' 'Japan' 'Iceland' 'Channel Islands' 'Denmark' 'Cyprus'\n",
            " 'Sweden' 'Austria' 'Israel' 'Finland' 'Bahrain' 'Greece' 'Hong Kong'\n",
            " 'Singapore' 'Lebanon' 'United Arab Emirates' 'Saudi Arabia'\n",
            " 'Czech Republic' 'Canada' 'Unspecified' 'Brazil' 'USA'\n",
            " 'European Community' 'Malta' 'RSA']\n"
          ]
        }
      ],
      "source": [
        "# Check unique values in the Country column\n",
        "unique_countries = df['Country'].unique()\n",
        "print(\"Unique values in 'Country' column:\", unique_countries)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Having confirmed this, we will now filter the data accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique values in 'Country' column after filtering: ['United Kingdom']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Filter the dataset to include only the United Kingdom\n",
        "df_uk = df[df['Country'] == 'United Kingdom']\n",
        "\n",
        "# Verify the filter by checking the unique countries again\n",
        "unique_countries_after_filter = df_uk['Country'].unique()\n",
        "print(\"Unique values in 'Country' column after filtering:\", unique_countries_after_filter)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will now begin to inspect the now filtered data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First few rows of the data:\n",
            "  InvoiceNo StockCode                          Description  Quantity  \\\n",
            "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
            "1    536365     71053                  WHITE METAL LANTERN         6   \n",
            "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
            "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
            "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
            "\n",
            "           InvoiceDate  UnitPrice  CustomerID         Country  \n",
            "0  2010-12-01 08:26:00       2.55       17850  United Kingdom  \n",
            "1  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n",
            "2  2010-12-01 08:26:00       2.75       17850  United Kingdom  \n",
            "3  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n",
            "4  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n"
          ]
        }
      ],
      "source": [
        "# Display the first few rows of the DataFrame to get an overview.\n",
        "print(\"First few rows of the data:\")\n",
        "print(df_uk.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Summary statistics for numerical columns:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quantity</th>\n",
              "      <th>UnitPrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>495478.000000</td>\n",
              "      <td>495478.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>8.605486</td>\n",
              "      <td>4.532422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>227.588756</td>\n",
              "      <td>99.315438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-80995.000000</td>\n",
              "      <td>-11062.060000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>4.130000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>80995.000000</td>\n",
              "      <td>38970.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Quantity      UnitPrice\n",
              "count  495478.000000  495478.000000\n",
              "mean        8.605486       4.532422\n",
              "std       227.588756      99.315438\n",
              "min    -80995.000000  -11062.060000\n",
              "25%         1.000000       1.250000\n",
              "50%         3.000000       2.100000\n",
              "75%        10.000000       4.130000\n",
              "max     80995.000000   38970.000000"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Summary statistics for numerical columns\n",
        "print(\"\\nSummary statistics for numerical columns:\")\n",
        "df_uk[['Quantity', 'UnitPrice']].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.2.2 Removing Null Rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Count of non-NA values in each column:\n",
            "InvoiceNo      495478\n",
            "StockCode      495478\n",
            "Description    494024\n",
            "Quantity       495478\n",
            "InvoiceDate    495478\n",
            "UnitPrice      495478\n",
            "CustomerID     495478\n",
            "Country        495478\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Display the count of non null values in each column\n",
        "print(\"\\nCount of non-NA values in each column:\")\n",
        "print(df_uk.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Missing values in each column:\n",
            "InvoiceNo         0\n",
            "StockCode         0\n",
            "Description    1454\n",
            "Quantity          0\n",
            "InvoiceDate       0\n",
            "UnitPrice         0\n",
            "CustomerID        0\n",
            "Country           0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nMissing values in each column:\")\n",
        "print(df_uk.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.2.3 Truncating the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In terms of technical feasibility, truncating the dataset was a necessary decision. The full filtered dataset for the UK subset contains upwards of 400,000 records.\n",
        "\n",
        "This reduction in size will allow us to focus on a representative sample of the data and ensure that the analysis remains efficient, whilst aligning with the stakeholder requirements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(50000, 8)\n",
            "  InvoiceNo StockCode                          Description  Quantity  \\\n",
            "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
            "1    536365     71053                  WHITE METAL LANTERN         6   \n",
            "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
            "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
            "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
            "\n",
            "           InvoiceDate  UnitPrice  CustomerID         Country  \n",
            "0  2010-12-01 08:26:00       2.55       17850  United Kingdom  \n",
            "1  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n",
            "2  2010-12-01 08:26:00       2.75       17850  United Kingdom  \n",
            "3  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n",
            "4  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n"
          ]
        }
      ],
      "source": [
        "df_truncated = df_uk.head(50000)\n",
        "\n",
        "# Verifies the truncation\n",
        "print(df_truncated.shape)\n",
        "print(df_truncated.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Having previously ascertained that the only missing values in the dataset were in the **Description** column, we can delete those particular rows. \n",
        "\n",
        "The rationale behind this decision mainly lies in the fact that our stakeholder wishes to gather insights on product trends, null values for product names will be unhelpful for this analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values in 'Description' column before: 158\n",
            "Shape before deletion: (50000, 8)\n"
          ]
        }
      ],
      "source": [
        "missing_before = df_truncated['Description'].isna().sum()\n",
        "print(\"Missing values in 'Description' column before:\", missing_before)\n",
        "\n",
        "# Delete rows with missing values in 'Description'\n",
        "df_truncated_cleaned = df_truncated.dropna(subset=['Description'])\n",
        "print(f\"Shape before deletion: {df_truncated.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values in 'Description' after deletion: 0\n",
            "Shape after deletion: (49842, 8)\n"
          ]
        }
      ],
      "source": [
        "# Check the count of missing values in 'Description' after deletion\n",
        "missing_after = df_truncated_cleaned['Description'].isna().sum()\n",
        "print(f\"Missing values in 'Description' after deletion: {missing_after}\")\n",
        "\n",
        "print(f\"Shape after deletion: {df_truncated_cleaned.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Remaining null values in the dataset:\n",
            "InvoiceNo      0\n",
            "StockCode      0\n",
            "Description    0\n",
            "Quantity       0\n",
            "InvoiceDate    0\n",
            "UnitPrice      0\n",
            "CustomerID     0\n",
            "Country        0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check for any remaining NA values in the dataset\n",
        "na_check = df_truncated_cleaned.isna().sum()\n",
        "print(\"Remaining null values in the dataset:\")\n",
        "print(na_check)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.2.4 Transforming invalid inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- remove negative + 0 values for price and qty? why? b/c can't buy 0 items.. + can't pay negative\n",
        "\n",
        "- some rows contain neg, likely indicates data entry error or anomaly w/ transactiosns\n",
        "\n",
        "for purpose of this analysis and tp prvent skewed results and to ensure data integrity - removing these rwos.\n",
        "\n",
        "unknown if returns or refunds, "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after removing rows with negative values: (49019, 8)\n"
          ]
        }
      ],
      "source": [
        "# Remove rows with negative values in Quantity or UnitPrice\n",
        "df_truncated_cleaned = df_truncated_cleaned[(df_truncated_cleaned['Quantity'] >= 0) & (df_truncated_cleaned['UnitPrice'] >= 0)]\n",
        "\n",
        "# Verify the shape after removal\n",
        "print(f\"Shape after removing rows with negative values: {df_truncated_cleaned.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.2.5 Feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- break down invoice date into year, month, day, hour\n",
        "- create new col revenue total per item purchase, \n",
        "- create new col revenue per year, month, day\n",
        "- break items into categories and colour? dep. on num of unique values...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Invoice date must be transformed into datetime format to easily break separate + analyse transaction patterns, good for later on peak times to entice customers with discount codes etc. to inc. revenue.\n",
        "\n",
        "break time into hour bc 24 hours is more manageable than smaller components - can utilise in analysis of popular timings\n",
        "\n",
        "analyse time based trends effectively with broken down dates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          InvoiceDate  Year  Month  Day  Hour\n",
            "0 2010-12-01 08:26:00  2010     12    1     8\n",
            "1 2010-12-01 08:26:00  2010     12    1     8\n",
            "2 2010-12-01 08:26:00  2010     12    1     8\n",
            "3 2010-12-01 08:26:00  2010     12    1     8\n",
            "4 2010-12-01 08:26:00  2010     12    1     8\n"
          ]
        }
      ],
      "source": [
        "# Breaking Invoice Date into multiple columns\n",
        "\n",
        "# We need to ensure the column is treated as a datetime format as opposed to a string\n",
        "df_truncated_cleaned['InvoiceDate'] = pd.to_datetime(df_truncated_cleaned['InvoiceDate'])\n",
        "\n",
        "# Extract the year, month, day, hour from the 'InvoiceDate' column\n",
        "df_truncated_cleaned['Year'] = df_truncated_cleaned['InvoiceDate'].dt.year\n",
        "df_truncated_cleaned['Month'] = df_truncated_cleaned['InvoiceDate'].dt.month\n",
        "df_truncated_cleaned['Day'] = df_truncated_cleaned['InvoiceDate'].dt.day\n",
        "df_truncated_cleaned['Hour'] = df_truncated_cleaned['InvoiceDate'].dt.hour\n",
        "\n",
        "# Display the first few rows of the DataFrame to confirm the changes\n",
        "print(df_truncated_cleaned[['InvoiceDate', 'Year', 'Month', 'Day', 'Hour']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We utilise the `to_datetime()` function to ensure the type is set as a datetime variable, rather than a string variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.2.5 Calculating Aggregated Revenues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the total amount spent per transaction and store in new col\n",
        "df_truncated_cleaned['TotalAmount'] = df_truncated_cleaned['Quantity'] * df_truncated_cleaned['UnitPrice']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have successfully calculcated revenue per transaction, we can aggregate by year, month and day and store each in a csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique years: 2\n",
            "Number of unique months: 2\n",
            "Number of unique days: 22\n",
            "Number of unique hours: 14\n"
          ]
        }
      ],
      "source": [
        "unique_year = df_truncated_cleaned['Year'].nunique()\n",
        "print(f\"Number of unique years: {unique_year}\")\n",
        "\n",
        "unique_months = df_truncated_cleaned['Month'].nunique()\n",
        "print(f\"Number of unique months: {unique_months}\")\n",
        "\n",
        "unique_days = df_truncated_cleaned['Day'].nunique()\n",
        "print(f\"Number of unique days: {unique_days}\")\n",
        "\n",
        "unique_times = df_truncated_cleaned['Hour'].nunique()\n",
        "print(f\"Number of unique hours: {unique_times}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregate revenue by year, month, day, and hour\n",
        "revenue_by_year = df_truncated_cleaned.groupby('Year')['TotalAmount'].sum().reset_index()\n",
        "revenue_by_month = df_truncated_cleaned.groupby(['Year', 'Month'])['TotalAmount'].sum().reset_index()\n",
        "revenue_by_day = df_truncated_cleaned.groupby(['Year', 'Month', 'Day'])['TotalAmount'].sum().reset_index()\n",
        "revenue_by_hour = df_truncated_cleaned.groupby(['Year', 'Month', 'Day', 'Hour'])['TotalAmount'].sum().reset_index()\n",
        "\n",
        "# Rename the 'TotalAmount' column to the desired naming convention\n",
        "revenue_by_year = revenue_by_year.rename(columns={'TotalAmount': 'revenue_per_year'})\n",
        "revenue_by_month = revenue_by_month.rename(columns={'TotalAmount': 'revenue_per_month'})\n",
        "revenue_by_day = revenue_by_day.rename(columns={'TotalAmount': 'revenue_per_day'})\n",
        "revenue_by_hour = revenue_by_hour.rename(columns={'TotalAmount': 'revenue_per_hour'})\n",
        "\n",
        "# Round the revenue values to 2 decimal places\n",
        "revenue_by_year['revenue_per_year'] = revenue_by_year['revenue_per_year'].round(2)\n",
        "revenue_by_month['revenue_per_month'] = revenue_by_month['revenue_per_month'].round(2)\n",
        "revenue_by_day['revenue_per_day'] = revenue_by_day['revenue_per_day'].round(2)\n",
        "revenue_by_hour['revenue_per_hour'] = revenue_by_hour['revenue_per_hour'].round(2)\n",
        "\n",
        "# Export each aggregation to a separate CSV\n",
        "revenue_by_year.to_csv('revenue_by_year.csv', index=False)\n",
        "revenue_by_month.to_csv('revenue_by_month.csv', index=False)\n",
        "revenue_by_day.to_csv('revenue_by_day.csv', index=False)\n",
        "revenue_by_hour.to_csv('revenue_by_hour.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>revenue_per_year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010</td>\n",
              "      <td>748268.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011</td>\n",
              "      <td>190982.63</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Year  revenue_per_year\n",
              "0  2010         748268.98\n",
              "1  2011         190982.63"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "revenue_by_year.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>revenue_per_month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010</td>\n",
              "      <td>12</td>\n",
              "      <td>748268.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>190982.63</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Year  Month  revenue_per_month\n",
              "0  2010     12          748268.98\n",
              "1  2011      1          190982.63"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "revenue_by_month.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>revenue_per_day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>54818.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>47570.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>41308.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>25853.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>53322.12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Year  Month  Day  revenue_per_day\n",
              "0  2010     12    1         54818.08\n",
              "1  2010     12    2         47570.53\n",
              "2  2010     12    3         41308.69\n",
              "3  2010     12    5         25853.20\n",
              "4  2010     12    6         53322.12"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "revenue_by_day.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "      <th>revenue_per_hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>527.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>7356.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>4877.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>4041.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>7447.92</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Year  Month  Day  Hour  revenue_per_hour\n",
              "0  2010     12    1     8            527.95\n",
              "1  2010     12    1     9           7356.39\n",
              "2  2010     12    1    10           4877.56\n",
              "3  2010     12    1    11           4041.56\n",
              "4  2010     12    1    12           7447.92"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "revenue_by_hour.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.2.6 Top 10 customers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are now interested in calculating revenue per each individual customer so that we can assess the top 10 customers.\n",
        "\n",
        "We will be saving this revenue per customer data in a new CSV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique customers: 929\n"
          ]
        }
      ],
      "source": [
        "unique_customers = df_truncated_cleaned['CustomerID'].nunique()\n",
        "print(f\"Number of unique customers: {unique_customers}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First few rows of revenue per customer:\n",
            "   CustomerID  Revenue\n",
            "0       12747   706.27\n",
            "1       12748  4479.43\n",
            "2       12826   155.00\n",
            "3       12829   293.00\n",
            "4       12838   390.79\n",
            "\n",
            "\n",
            "Top 10 customers by revenue:\n",
            "     CustomerID    Revenue\n",
            "384       15287  280583.57\n",
            "904       18102   27834.61\n",
            "469       15749   22998.40\n",
            "350       15061   21324.65\n",
            "766       17450   20649.04\n",
            "521       16029   13202.52\n",
            "774       17511   10573.22\n",
            "46        13089    7738.67\n",
            "550       16210    7000.64\n",
            "149       13777    6961.78\n"
          ]
        }
      ],
      "source": [
        "revenue_per_customer = df_truncated_cleaned.groupby('CustomerID')['TotalAmount'].sum().reset_index()\n",
        "revenue_per_customer.rename(columns={'TotalAmount': 'Revenue'}, inplace=True)\n",
        "\n",
        "# Display the first few rows of the DataFrame \n",
        "print(\"First few rows of revenue per customer:\")\n",
        "print(revenue_per_customer.head())\n",
        "print(\"\\n\")\n",
        "\n",
        "# top 10 customers by revenue\n",
        "top_10_customers = revenue_per_customer.sort_values(by='Revenue', ascending=False).head(10)\n",
        "print(\"Top 10 customers by revenue:\")\n",
        "print(top_10_customers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "revenue_per_customer.to_csv('revenue_per_customer.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Having examined the CSV file we can see that the revenue values extend 2 decimal places, therefore we will need to truncate these down."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "revenue_per_customer = pd.read_csv('revenue_per_customer.csv')\n",
        "revenue_per_customer['Revenue']=revenue_per_customer['Revenue'].round(2)\n",
        "revenue_per_customer.to_csv('revenue_per_customer.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.2.7 Creating category columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Round off total amount values to 2 decimal places\n",
        "df_truncated_cleaned['TotalAmount'] = df_truncated_cleaned['TotalAmount'].round(2)\n",
        "#Save current DataFrame to a CSV file\n",
        "df_truncated_cleaned.to_csv('online_retail_cleaned.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will utilise ChatGPT to apply a keyword-based categorisation upon the dataset we have. This will ensure more accurate categorisation and handle the large volume of records quickly and consistently. This will reduce human error in category selection and application, proving it to be more reliable compared to manual methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'online_retail_categorized.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/mahahussain/Desktop/Hackathon2/Online_Retail_Sales_Analysis/jupyter_notebooks/Notebook_Template.ipynb Cell 76\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mahahussain/Desktop/Hackathon2/Online_Retail_Sales_Analysis/jupyter_notebooks/Notebook_Template.ipynb#Y135sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m categorised_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39monline_retail_categorized.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mahahussain/Desktop/Hackathon2/Online_Retail_Sales_Analysis/jupyter_notebooks/Notebook_Template.ipynb#Y135sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# View generated category list\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mahahussain/Desktop/Hackathon2/Online_Retail_Sales_Analysis/jupyter_notebooks/Notebook_Template.ipynb#Y135sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m categorised_df[\u001b[39m\"\u001b[39m\u001b[39mCategory\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39munique()\n",
            "File \u001b[0;32m~/Desktop/Hackathon2/Online_Retail_Sales_Analysis/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[0;32m~/Desktop/Hackathon2/Online_Retail_Sales_Analysis/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m~/Desktop/Hackathon2/Online_Retail_Sales_Analysis/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
            "File \u001b[0;32m~/Desktop/Hackathon2/Online_Retail_Sales_Analysis/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
            "File \u001b[0;32m~/Desktop/Hackathon2/Online_Retail_Sales_Analysis/.venv/lib/python3.12/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'online_retail_categorized.csv'"
          ]
        }
      ],
      "source": [
        "categorised_df = pd.read_csv('online_retail_categorized.csv')\n",
        "\n",
        "# View generated category list\n",
        "categorised_df[\"Category\"].unique()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Category Counts:\n",
            "Category\n",
            "Other                     26581\n",
            "Drinkware                  3461\n",
            "Accessories                3375\n",
            "Home Decor                 2860\n",
            "Seasonal                   2634\n",
            "Storage & Organization     2592\n",
            "Heating & Warmth           1944\n",
            "Stationery                 1418\n",
            "Tableware                  1275\n",
            "Gardening                  1160\n",
            "Photo & Frames              725\n",
            "Timepieces                  679\n",
            "Toys & Games                315\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Category Counts\n",
        "# Calculate the count of each category in the 'Category' column of the 'categorised_df' DataFrame\n",
        "category_counts = categorised_df['Category'].value_counts()\n",
        "print(\"Category Counts:\")\n",
        "print(category_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.2.8 Categories & Revenue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 10 categories by items purchased:\n",
            "Category\n",
            "Other                     26581\n",
            "Drinkware                  3461\n",
            "Accessories                3375\n",
            "Home Decor                 2860\n",
            "Seasonal                   2634\n",
            "Storage & Organization     2592\n",
            "Heating & Warmth           1944\n",
            "Stationery                 1418\n",
            "Tableware                  1275\n",
            "Gardening                  1160\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "Top 10 categories by revenue:\n",
            "                  Category  TotalAmount\n",
            "5                    Other    507229.88\n",
            "3         Heating & Warmth     74786.31\n",
            "4               Home Decor     68422.84\n",
            "0              Accessories     62248.68\n",
            "1                Drinkware     52585.97\n",
            "9   Storage & Organization     51482.13\n",
            "7                 Seasonal     39110.05\n",
            "6           Photo & Frames     22442.31\n",
            "10               Tableware     20860.83\n",
            "2                Gardening     15125.57\n"
          ]
        }
      ],
      "source": [
        "# In terms of items purchased\n",
        "print(\"\\nTop 10 categories by items purchased:\")\n",
        "top_10_categories = category_counts.sort_values(ascending=False).head(10)\n",
        "print(top_10_categories)\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# In terms of revenue generated\n",
        "print(\"Top 10 categories by revenue:\")\n",
        "revenue_by_category = categorised_df.groupby('Category')['TotalAmount'].sum().reset_index()\n",
        "top_10_revenue_categories = revenue_by_category.sort_values(by='TotalAmount', ascending=False).head(10)\n",
        "print(top_10_revenue_categories)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.2.9 Subcategorising 'Other' Category"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To address the 26k+ records currently categorised as 'Other' we utilised generative AI once more to break down the Other category into subcategories to refine it.\n",
        "\n",
        "Upon its analysis, it was found that no clear sub categories emerged. The records largely consisted of miscellaneous items, inlcuding products such as dust bins, garlands, cupcake cases, and other similar items. \n",
        "\n",
        "In future analysis, further refinement of product categories could be explored."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.3 Category Price Bins"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To better understand the distribution of product prices in the dataset, we applied a price binning strategy to categorise the prodcuts into defined price ranges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Price Range Counts:\n",
            "PriceRange\n",
            "0-10        46364\n",
            "11-50        2559\n",
            "101-500        51\n",
            "501-1000       29\n",
            "51-100         14\n",
            "1000+           2\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Define bins and labels for unit price\n",
        "bins = [0, 10, 50, 100, 500, 1000, float('inf')]  # 6 bins for price ranges\n",
        "labels = ['0-10', '11-50', '51-100', '101-500', '501-1000', '1000+']  # 6 labels to match the bins\n",
        "\n",
        "\n",
        "\n",
        "# Bin prices and store in a new column\n",
        "categorised_df['PriceRange'] = pd.cut(categorised_df['UnitPrice'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Count of each price range\n",
        "price_range_counts = categorised_df['PriceRange'].value_counts()\n",
        "\n",
        "print(\"Price Range Counts:\")\n",
        "print(price_range_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the cleaned, categorised and price-binned DataFrame to a CSV file\n",
        "categorised_df.to_csv('UK_online_retail_final.csv', index=False)\n",
        "\n",
        "# Delete unncessary CSV files:\n",
        "os.remove('online_retail_cleaned.csv')\n",
        "os.remove('online_retail_categorized.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Section 2 : VISUALISATIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 2 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test\n"
          ]
        }
      ],
      "source": [
        "print(\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In cases where you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "expected an indented block after 'try' statement on line 2 (553063055.py, line 5)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[41], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    except Exception as e:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'try' statement on line 2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "try:\n",
        "  # create your folder here\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
